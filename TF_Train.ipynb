{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-27 17:40:46.028326: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-27 17:40:47.496202: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "2.13.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-27 17:40:49.449304: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:09:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-07-27 17:40:49.472492: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:09:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-07-27 17:40:49.472976: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:09:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.applications import VGG16\n",
    "from keras import layers, models\n",
    "from tqdm import tqdm\n",
    "\n",
    "import os\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "print(tf.__version__)\n",
    "\n",
    "\n",
    "# Prepare the dataset using tf.data.Dataset\n",
    "def prepare_dataset(data_dir, batch_size):\n",
    "    print(\"Preparing the dataset...\")\n",
    "    train_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "        data_dir,\n",
    "        image_size=(224, 224),\n",
    "        batch_size=batch_size,\n",
    "        label_mode='categorical',\n",
    "        labels='inferred',\n",
    "        validation_split=0.2,\n",
    "        subset='training',\n",
    "        seed=42\n",
    "    )\n",
    "\n",
    "    validation_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "        data_dir,\n",
    "        image_size=(224, 224),\n",
    "        batch_size=batch_size,\n",
    "        label_mode='categorical',\n",
    "        labels='inferred',\n",
    "        validation_split=0.2,\n",
    "        subset='validation',\n",
    "        seed=42\n",
    "    )\n",
    "\n",
    "    print(\"Dataset preparation complete.\")\n",
    "    return train_dataset, validation_dataset\n",
    "\n",
    "# Release GPU memory when done or interrupted\n",
    "def release_gpu_memory():\n",
    "    print(\"Releasing GPU memory...\")\n",
    "    tf.keras.backend.clear_session()\n",
    "    print(\"GPU memory released.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing the dataset...\n",
      "Found 127132 files belonging to 4 classes.\n",
      "Using 101706 files for training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-27 17:41:08.381039: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:09:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-07-27 17:41:08.381373: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:09:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-07-27 17:41:08.381640: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:09:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-07-27 17:41:09.428225: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:09:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-07-27 17:41:09.428552: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:09:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-07-27 17:41:09.428567: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-07-27 17:41:09.428819: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:09:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-07-27 17:41:09.428875: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3888 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2060, pci bus id: 0000:09:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 127132 files belonging to 4 classes.\n",
      "Using 25426 files for validation.\n",
      "Dataset preparation complete.\n"
     ]
    }
   ],
   "source": [
    "# Specify the paths\n",
    "data_dir = \"Dataset/Rotated Images\"\n",
    "batch_size = 16\n",
    "\n",
    "# Prepare the dataset\n",
    "train_dataset, validation_dataset = prepare_dataset(data_dir, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building the model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model building complete.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import BatchNormalization\n",
    "\n",
    "def build_model(num_classes):\n",
    "    print(\"Building the model...\")\n",
    "    base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "    # Freeze the layers in the base model\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    x = base_model.output\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(4096, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)  # Add BatchNormalization layer here\n",
    "    x = layers.Dropout(0.7)(x)\n",
    "    x = layers.Dense(4096, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)  # Add BatchNormalization layer here\n",
    "    x = layers.Dropout(0.7)(x)\n",
    "    predictions = layers.Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = models.Model(inputs=base_model.input, outputs=predictions)\n",
    "    print(\"Model building complete.\")\n",
    "    return model\n",
    "\n",
    "\n",
    "# Build the model\n",
    "\n",
    "# Number of classes (4 rotations: 0, 90, 180, 270)\n",
    "num_classes = 4\n",
    "\n",
    "model = build_model(num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile and train the model\n",
    "def train_model(model, train_dataset, validation_dataset, num_epochs):\n",
    "    try:\n",
    "        print(\"Compiling the model...\")\n",
    "        # Custom learning rate (choose your desired learning rate)\n",
    "        learning_rate = 0.0001\n",
    "\n",
    "        # Create a custom Adam optimizer with the desired learning rate\n",
    "        optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=learning_rate)\n",
    "        model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        print(\"Model compilation complete.\")\n",
    "\n",
    "        print(\"Training the model...\")\n",
    "        for epoch in tqdm(range(num_epochs), desc=\"Epochs\"):\n",
    "            model.fit(train_dataset, validation_data=validation_dataset, epochs=1)\n",
    "        print(\"Model training complete.\")\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Training interrupted.\")\n",
    "    finally:\n",
    "        # Release GPU memory when done or interrupted\n",
    "        release_gpu_memory()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling the model...\n",
      "Model compilation complete.\n",
      "Training the model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-27 17:41:32.966749: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8902\n",
      "2023-07-27 17:41:34.250186: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2023-07-27 17:41:35.497946: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.54GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-07-27 17:41:36.000873: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.30GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-07-27 17:41:36.448806: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.21GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1/6357 [..............................] - ETA: 12:02:21 - loss: 2.1653 - accuracy: 0.4375"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-27 17:41:36.846203: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.22GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6356/6357 [============================>.] - ETA: 0s - loss: 0.4969 - accuracy: 0.8604"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-27 17:50:03.319787: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.35GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-07-27 17:50:03.797754: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.21GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6357/6357 [==============================] - 604s 94ms/step - loss: 0.4970 - accuracy: 0.8604 - val_loss: 0.1885 - val_accuracy: 0.9314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  10%|█         | 1/10 [10:03<1:30:35, 603.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6357/6357 [==============================] - 595s 94ms/step - loss: 0.2555 - accuracy: 0.9090 - val_loss: 0.1688 - val_accuracy: 0.9372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  20%|██        | 2/10 [19:59<1:19:50, 598.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6357/6357 [==============================] - 597s 94ms/step - loss: 0.1978 - accuracy: 0.9258 - val_loss: 0.1778 - val_accuracy: 0.9349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  30%|███       | 3/10 [29:56<1:09:46, 598.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6357/6357 [==============================] - 593s 93ms/step - loss: 0.1621 - accuracy: 0.9378 - val_loss: 0.1643 - val_accuracy: 0.9427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  40%|████      | 4/10 [39:49<59:37, 596.18s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6357/6357 [==============================] - 598s 94ms/step - loss: 0.1392 - accuracy: 0.9473 - val_loss: 0.1771 - val_accuracy: 0.9417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  50%|█████     | 5/10 [49:47<49:43, 596.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6357/6357 [==============================] - 596s 94ms/step - loss: 0.1220 - accuracy: 0.9547 - val_loss: 0.1698 - val_accuracy: 0.9403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  60%|██████    | 6/10 [59:42<39:45, 596.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6357/6357 [==============================] - 595s 94ms/step - loss: 0.1089 - accuracy: 0.9588 - val_loss: 0.1702 - val_accuracy: 0.9432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  70%|███████   | 7/10 [1:09:38<29:47, 596.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6357/6357 [==============================] - 600s 94ms/step - loss: 0.0971 - accuracy: 0.9641 - val_loss: 0.1752 - val_accuracy: 0.9448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  80%|████████  | 8/10 [1:19:38<19:54, 597.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6357/6357 [==============================] - 598s 94ms/step - loss: 0.0910 - accuracy: 0.9663 - val_loss: 0.1938 - val_accuracy: 0.9403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  90%|█████████ | 9/10 [1:29:35<09:57, 597.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6357/6357 [==============================] - 600s 94ms/step - loss: 0.0820 - accuracy: 0.9701 - val_loss: 0.1859 - val_accuracy: 0.9454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs: 100%|██████████| 10/10 [1:39:35<00:00, 597.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training complete.\n",
      "Releasing GPU memory...\n",
      "GPU memory released.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Training parameters\n",
    "num_epochs = 10\n",
    "\n",
    "# Train the model\n",
    "train_model(model, train_dataset, validation_dataset, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to: Model/\n"
     ]
    }
   ],
   "source": [
    "from keras.models import save_model\n",
    "\n",
    "def save_trained_model(model, save_path):\n",
    "    save_model(model, save_path)\n",
    "    print(\"Model saved to:\", save_path)\n",
    "\n",
    "\n",
    "save_path = \"Model/\"  # Replace with your desired path\n",
    "save_trained_model(model, save_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
